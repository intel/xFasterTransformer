[qwen2]
model_name = /data/models/Qwen1.5-72B-Chat
head_num = 64
kv_head_num = 64
size_per_head = 128
inter_size = 24576
max_pos_seq_len = 32768
num_layer = 80
rms_norm_eps = 1e-06
layernorm_type = pre_layernorm
activation_type = silu
rope_theta = 1000000.0
has_post_decoder_layernorm = 1
vocab_size = 152064
start_id = 151643
end_id = 151645
pad_id = 151643
weight_data_type = fp16

