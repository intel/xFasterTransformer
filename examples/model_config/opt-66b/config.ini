[gpt]
model_name = /data/models/opt-66b/
head_num = 72
size_per_head = 128
inter_size = 36864
max_pos_seq_len = 2048
num_layer = 64
layernorm_eps = 1e-5
layernorm_type = pre_layernorm
activation_type = Relu
has_post_decoder_layernorm = 1
vocab_size = 50272
start_id = 2
end_id = 2
weight_data_type = fp16